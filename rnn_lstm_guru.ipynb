{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdO4ORhGi453XiBlUgOvL7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation of built-in RNN in Pytorch for Digit classification on MNIST dataset**"
      ],
      "metadata": {
        "id": "4uRYS5duVZT4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1VNRNCTV4sSt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "BYMyHJqwCYqF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "num_classes = 10\n",
        "input_size = 28\n",
        "sequence_length = 28\n",
        "hidden_size = 128 #so you can try out different sizes here\n",
        "num_layers = 2 #stacking two rnns together and 2 rnn takes input from 1 so this improves our model\n",
        "num_epochs = 2\n",
        "batch_size =100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "QxbfzV7C6kVX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MINST dataset\n",
        "#traindataset\n",
        "train_dataset = torchvision.datasets.MNIST(root ='./data',\n",
        "                                           train = True,\n",
        "                                           transform = transforms.ToTensor(),\n",
        "                                           download = True)"
      ],
      "metadata": {
        "id": "_BcAh1X-7W5d"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MINST dataset\n",
        "#testdataset\n",
        "test_dataset = torchvision.datasets.MNIST(root ='./data',\n",
        "                                           train = False,\n",
        "                                           transform = transforms.ToTensor())"
      ],
      "metadata": {
        "id": "Jd6Zt5WE9dl3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size =batch_size,\n",
        "                                          shuffle = True)"
      ],
      "metadata": {
        "id": "HMS5ANC9-6TS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fully connected RNN with one hidden layer\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size, num_layers, num_classes):\n",
        "    super(RNN, self).__init__()\n",
        "    #start the number of layer and the hidden size\n",
        "    self.num_layers =num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    # use builtin rnn model\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True) \n",
        "    # input needs to have shape (batch_size, seq , input_size)\n",
        "\n",
        "    # or:\n",
        "    #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    #creating fully connected linear layer input size hidden size, outpu size, num_classes   \n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Set initial hidden states h0 (and cell states for LSTM)\n",
        "    #create a tensor with 0, num_layers, batch size, hiddensize and \n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "   # c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        " \n",
        "    out, _ = self.rnn(x,h0)\n",
        "    #ouput: batch_size, seq_length, hidden_size \n",
        "    #out (N, 28, 128)\n",
        "    out = out[:,-1,:]\n",
        "    #out(N, 128)\n",
        "    out = self.fc(out)\n",
        "    return(out)\n",
        "\n"
      ],
      "metadata": {
        "id": "arsnR8e3_ipa"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
      ],
      "metadata": {
        "id": "bxZJKhLT_rXP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
      ],
      "metadata": {
        "id": "ui0Qf8J6DR9e"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # origin shape: [N, 1, 28, 28]\n",
        "        # resized: [N, 28, 28]\n",
        "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM_y3P8BDJcl",
        "outputId": "abafeb7a-a72e-4563-c75d-4765d39c26ad"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.8073\n",
            "Epoch [1/2], Step [200/600], Loss: 0.6427\n",
            "Epoch [1/2], Step [300/600], Loss: 0.5445\n",
            "Epoch [1/2], Step [400/600], Loss: 0.6915\n",
            "Epoch [1/2], Step [500/600], Loss: 0.3976\n",
            "Epoch [1/2], Step [600/600], Loss: 0.4456\n",
            "Epoch [2/2], Step [100/600], Loss: 0.2698\n",
            "Epoch [2/2], Step [200/600], Loss: 0.3522\n",
            "Epoch [2/2], Step [300/600], Loss: 0.1961\n",
            "Epoch [2/2], Step [400/600], Loss: 0.3390\n",
            "Epoch [2/2], Step [500/600], Loss: 0.2441\n",
            "Epoch [2/2], Step [600/600], Loss: 0.3292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRn1UyFeRCgm",
        "outputId": "272c2ace-181a-4c9d-f38b-239a869159f6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 92.21 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv8CTAPIV7OG",
        "outputId": "6b374d45-dcbd-4248-fdc2-bc67e672f5ec"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8, 9, 4, 3, 2, 6, 5, 5, 2, 5, 2, 8, 3, 0, 4, 0, 0, 0, 1, 3, 4, 4, 5, 2,\n",
            "        3, 4, 6, 3, 9, 2, 4, 2, 6, 5, 8, 3, 2, 8, 9, 4, 4, 0, 7, 7, 1, 1, 9, 6,\n",
            "        5, 6, 8, 8, 6, 7, 2, 6, 6, 5, 8, 6, 5, 4, 4, 7, 0, 4, 3, 1, 0, 2, 2, 7,\n",
            "        7, 2, 0, 2, 1, 5, 0, 6, 4, 7, 2, 0, 7, 1, 0, 3, 7, 3, 6, 3, 2, 9, 3, 1,\n",
            "        2, 4, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vkyanuwWDDH",
        "outputId": "62d8ea8b-7310-452e-cde2-110e10dd9bb6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-5.7448e-01, -1.7802e+00,  5.3725e-02,  1.9971e-01, -2.1774e+00,\n",
            "          1.8993e+00, -5.1161e+00,  2.2918e+00,  6.3161e+00,  1.9537e+00],\n",
            "        [-1.9496e+00, -5.9289e+00, -4.1073e+00, -7.1174e-01,  2.0318e+00,\n",
            "          4.3925e+00, -3.5486e+00,  9.2704e-01,  2.7550e-01,  4.8593e+00],\n",
            "        [-3.3459e+00, -2.9552e+00, -2.9616e+00, -3.5457e+00,  3.9183e+00,\n",
            "          1.1560e+00, -2.5586e+00,  4.6535e-01,  1.5720e+00,  5.8636e+00],\n",
            "        [-3.6531e+00,  7.1243e-01,  5.1045e-01,  8.2719e+00, -1.6936e+00,\n",
            "          1.7024e+00, -5.5046e+00,  5.0272e-01,  6.5211e-01,  3.5141e-01],\n",
            "        [ 5.9301e-01,  9.4463e-01,  7.6263e+00,  2.4947e+00, -5.6129e+00,\n",
            "          1.7633e-01, -2.7394e+00,  1.7234e+00,  1.2147e+00, -3.0250e+00],\n",
            "        [ 1.0247e+00, -1.4111e+00,  1.2491e-01, -7.2216e+00,  3.0961e+00,\n",
            "         -8.4544e-01,  5.6029e+00, -1.1623e+00, -3.1836e-01, -5.9234e-01],\n",
            "        [-1.1724e+00, -5.6222e+00, -3.4732e+00,  1.7602e+00,  4.1406e-01,\n",
            "          6.6424e+00, -4.0122e+00, -1.4244e+00,  1.2756e+00,  3.0394e+00],\n",
            "        [ 1.0913e+00, -3.9161e+00, -1.7587e+00,  2.4854e+00, -2.0992e+00,\n",
            "          6.3004e+00, -2.6178e+00, -1.4562e+00,  1.4941e+00,  3.0284e-01],\n",
            "        [-1.1442e-01,  1.9027e+00,  6.7841e+00,  3.0917e+00, -4.8237e+00,\n",
            "         -1.4849e-01, -1.4665e+00,  1.3313e+00,  8.1602e-01, -3.8876e+00],\n",
            "        [-2.3200e+00, -2.7520e+00, -3.2699e+00,  3.0484e+00,  1.8565e-01,\n",
            "          5.6233e+00, -3.6767e+00, -1.7434e+00,  1.0807e+00,  2.5248e+00],\n",
            "        [-5.6779e-01, -4.5892e-01,  7.4677e+00,  2.5327e-01, -1.3930e+00,\n",
            "         -2.5220e+00, -6.1758e-01,  8.9653e-01, -5.3990e-01, -2.7800e-01],\n",
            "        [-1.3225e+00, -9.9680e-01,  7.6590e-02,  2.2842e-01, -1.0701e+00,\n",
            "          1.7315e+00, -2.1172e+00, -1.4295e+00,  7.2007e+00, -1.3122e-01],\n",
            "        [-3.4041e+00,  2.2570e+00,  1.0246e+00,  6.6656e+00, -2.7667e+00,\n",
            "          2.1959e+00, -4.0211e+00,  3.9793e-01,  4.8879e-01, -9.8482e-01],\n",
            "        [ 9.2847e+00, -5.0600e+00,  1.3017e+00, -1.4433e+00, -4.6436e+00,\n",
            "          2.4909e+00,  8.6550e-02,  4.0817e-01,  1.4713e+00, -1.1354e+00],\n",
            "        [-5.7284e+00, -5.9723e-01, -3.5363e+00, -2.7487e+00,  7.5662e+00,\n",
            "          1.1828e+00,  3.2097e-01, -1.4179e+00, -8.7335e-01,  2.1681e+00],\n",
            "        [ 8.5294e+00, -3.9157e+00,  1.8384e+00,  1.9936e-01, -5.1371e+00,\n",
            "          2.3486e+00, -1.0361e+00,  7.6211e-01,  1.8156e+00, -1.4135e+00],\n",
            "        [ 6.2791e+00, -3.1221e+00,  2.2438e+00,  1.4520e+00, -5.1567e+00,\n",
            "          2.3745e+00, -3.0104e+00,  1.2413e+00,  2.8321e+00, -7.6445e-01],\n",
            "        [ 8.6217e+00, -4.6476e+00,  8.1966e-01, -2.3819e+00, -3.6269e+00,\n",
            "          2.1214e+00,  2.1878e+00, -8.1022e-01,  1.1363e+00, -2.0719e+00],\n",
            "        [-4.7263e+00,  4.9013e+00,  6.6964e-01, -2.3547e+00,  1.5364e+00,\n",
            "         -1.1119e+00, -2.8692e-01,  3.6929e-01,  4.3973e+00, -8.7406e-01],\n",
            "        [-3.2786e+00,  1.7896e+00,  8.5057e-01,  7.6204e+00, -2.5935e+00,\n",
            "          2.0682e+00, -4.1506e+00,  2.5778e-01,  4.6615e-01, -1.1435e+00],\n",
            "        [-2.7161e+00, -2.9388e+00, -2.7297e+00, -5.6012e+00,  6.4979e+00,\n",
            "          1.5088e-01,  3.5294e-01, -1.4819e+00,  5.1314e-01,  3.7806e+00],\n",
            "        [-4.9685e+00, -9.9808e-01, -4.8416e+00, -1.4022e+00,  6.6132e+00,\n",
            "          1.8318e+00, -6.4919e-01, -4.8529e-01, -1.4118e+00,  2.8421e+00],\n",
            "        [-2.7469e+00, -1.8752e+00, -1.2874e-01,  1.0508e+00,  8.2847e-01,\n",
            "          4.9001e+00, -1.0704e+00,  1.2448e+00, -1.2346e+00, -1.5654e+00],\n",
            "        [ 9.1957e-01,  7.7232e-01,  7.2284e+00,  1.3157e+00, -3.4325e+00,\n",
            "         -6.4360e-01,  7.3724e-01,  1.9882e-01,  5.9999e-01, -4.7908e+00],\n",
            "        [-3.9930e+00,  1.0253e+00,  5.0320e-01,  8.1007e+00, -1.6646e+00,\n",
            "          1.5539e+00, -5.0118e+00,  8.3437e-01,  4.4637e-01,  1.1454e-01],\n",
            "        [-5.2441e+00, -1.7887e+00, -1.1704e+00, -3.8727e+00,  7.3240e+00,\n",
            "          7.0155e-01,  4.2231e-01, -2.9301e+00,  3.5804e-01,  2.5683e+00],\n",
            "        [ 3.2735e+00, -2.6214e+00, -1.8251e-01, -4.0121e+00,  2.4648e-01,\n",
            "          1.4234e+00,  5.8816e+00, -2.9500e+00,  1.4692e+00, -3.3258e+00],\n",
            "        [-3.6535e+00, -7.5160e-01,  1.6714e+00,  6.0257e+00, -2.1299e+00,\n",
            "          2.1477e+00, -7.6789e+00,  3.7352e+00,  5.4202e-01,  2.0820e+00],\n",
            "        [-1.3209e+00, -4.8891e+00, -3.6861e+00, -1.0600e+00,  1.3533e+00,\n",
            "          3.7346e+00, -3.8055e+00,  1.6056e+00, -4.9279e-01,  6.2181e+00],\n",
            "        [ 2.6243e+00, -5.3890e-01,  6.9885e+00,  3.5159e+00, -5.3788e+00,\n",
            "          6.4326e-01, -1.6151e+00,  5.3556e-01,  1.5576e+00, -4.0557e+00],\n",
            "        [-2.1446e+00, -4.6110e+00, -3.2932e+00, -4.5365e+00,  5.2640e+00,\n",
            "          1.1520e+00, -5.7081e-01, -3.7113e-01,  3.4255e-01,  4.9577e+00],\n",
            "        [-4.9394e-01,  2.5152e+00,  6.9948e+00,  2.5798e+00, -4.6733e+00,\n",
            "         -8.6677e-01, -1.5432e+00,  1.6458e+00,  7.3655e-01, -3.5180e+00],\n",
            "        [ 4.4435e+00, -4.0565e+00, -6.9959e-02, -6.0975e+00,  9.6065e-01,\n",
            "          4.5338e-01,  3.9023e+00, -1.6306e+00,  8.6538e-01,  3.5282e-02],\n",
            "        [-1.2291e+00, -4.6009e+00, -3.6110e+00,  3.3575e+00, -5.4281e-01,\n",
            "          6.8842e+00, -5.4899e+00, -4.6643e-01,  8.0278e-01,  3.3072e+00],\n",
            "        [-1.9156e+00, -1.3328e+00,  4.0062e-01,  4.8612e-01, -1.1054e+00,\n",
            "          2.0774e+00, -2.9915e+00, -6.4559e-01,  6.8524e+00,  4.1790e-01],\n",
            "        [-3.0461e+00,  1.0858e+00,  7.5257e-01,  7.6971e+00, -2.6223e+00,\n",
            "          2.3399e+00, -4.4614e+00,  8.6016e-01,  2.4270e-01, -7.5661e-01],\n",
            "        [ 4.1878e-01,  9.1252e-01,  7.1635e+00,  3.0124e+00, -5.5215e+00,\n",
            "          6.7503e-01, -2.5965e+00,  1.3978e+00,  5.4450e-01, -2.9492e+00],\n",
            "        [-2.2555e+00, -2.7094e+00, -6.5886e-01,  2.6484e-01, -3.0489e-01,\n",
            "          2.9349e+00, -2.4746e+00, -7.2340e-01,  6.0254e+00,  1.3527e+00],\n",
            "        [-4.1771e+00, -3.2528e+00, -4.5251e+00, -4.1089e-01,  4.0373e+00,\n",
            "          3.1544e+00, -2.7123e+00,  8.0191e-03, -3.8658e-01,  5.2774e+00],\n",
            "        [-5.1251e+00, -1.9231e+00, -3.0568e+00, -3.5629e+00,  7.7992e+00,\n",
            "          1.0859e+00,  5.1810e-02, -2.1911e+00, -8.8439e-01,  3.3122e+00],\n",
            "        [-2.0315e+00, -4.4992e+00, -3.3731e+00, -2.9343e+00,  3.9477e+00,\n",
            "          2.3803e+00, -1.5755e+00, -6.5444e-01,  1.4779e+00,  4.3136e+00],\n",
            "        [ 8.9210e+00, -4.9271e+00,  5.4055e-01, -2.6317e+00, -3.6178e+00,\n",
            "          2.0565e+00,  1.6333e+00, -2.6484e-01,  1.2062e+00, -1.4568e+00],\n",
            "        [-3.0000e+00,  1.1324e-01,  9.0128e-01,  3.1416e+00, -2.7405e+00,\n",
            "          1.1615e+00, -6.6277e+00,  8.8616e+00, -1.4953e+00,  2.2798e+00],\n",
            "        [-4.6868e+00,  5.5696e-01, -1.0727e+00,  2.4566e+00, -7.2004e-01,\n",
            "          2.3103e+00, -4.7264e+00,  6.4973e+00, -1.5154e+00,  2.1104e+00],\n",
            "        [-4.6626e+00,  9.2887e+00,  9.3090e-01, -1.3738e+00,  3.7018e-01,\n",
            "         -4.4861e+00,  1.0780e+00,  1.6723e+00,  1.9089e+00, -7.8104e-01],\n",
            "        [-4.7007e+00,  8.5945e+00,  7.4781e-01, -1.4488e+00,  6.2848e-01,\n",
            "         -3.8830e+00,  7.4435e-01,  1.5253e+00,  2.6565e+00, -7.7170e-01],\n",
            "        [-2.9227e+00, -3.1668e+00, -3.4204e+00,  4.8288e-01,  1.6779e+00,\n",
            "          4.6304e+00, -3.7362e+00,  1.4429e-02,  8.0423e-01,  3.5275e+00],\n",
            "        [ 4.3901e-01, -1.1891e+00,  3.4474e-01, -3.4278e+00,  8.6154e-01,\n",
            "          1.1558e+00,  6.2035e+00, -2.6551e+00,  2.1161e+00, -3.3851e+00],\n",
            "        [-2.9159e+00, -5.0730e-01, -2.7681e+00,  4.5664e+00, -8.5891e-01,\n",
            "          4.4573e+00, -3.9366e+00, -1.8311e-01,  2.3952e-02,  2.0660e+00],\n",
            "        [ 2.2384e+00, -2.3618e+00,  5.5288e-01, -3.2621e+00,  1.9558e-01,\n",
            "          1.2823e+00,  6.1436e+00, -1.4147e+00, -3.9423e-01, -3.7072e+00],\n",
            "        [-1.7460e+00, -1.0596e+00, -3.2078e-01,  9.2552e-01, -4.8208e-01,\n",
            "          2.6393e+00, -1.0705e+00, -2.0238e+00,  6.0194e+00, -8.5228e-01],\n",
            "        [-1.8078e+00, -7.6540e-01, -5.2099e-01, -6.1630e-01,  1.7112e-01,\n",
            "          3.0942e+00,  4.8074e-01, -2.2876e+00,  5.3986e+00, -1.9278e+00],\n",
            "        [ 4.2101e+00, -2.9075e+00, -3.1617e-01, -5.9146e+00,  8.7772e-01,\n",
            "          5.0562e-01,  5.5706e+00, -1.5997e+00,  1.7381e-01, -1.8066e+00],\n",
            "        [-4.1102e+00,  4.0766e-01,  1.6329e+00,  3.0584e+00, -2.6403e+00,\n",
            "          6.5783e-01, -6.4297e+00,  8.6804e+00, -7.8389e-01,  2.1729e+00],\n",
            "        [-4.0754e-01,  1.7245e+00,  6.4043e+00,  3.7150e+00, -4.8679e+00,\n",
            "          6.4947e-01, -1.8929e+00,  1.1945e+00,  3.2730e-01, -3.4659e+00],\n",
            "        [ 9.0050e-01, -1.4740e+00,  2.4310e-01, -5.5825e+00,  1.9226e+00,\n",
            "         -1.3124e-01,  6.8585e+00, -1.4248e+00, -2.7025e-01, -1.9774e+00],\n",
            "        [-2.6241e-01, -1.9022e+00, -2.0189e+00, -2.3737e+00,  1.0449e+00,\n",
            "          3.0982e+00,  2.1860e+00, -2.0889e+00,  3.6971e+00, -2.0164e+00],\n",
            "        [-8.0055e-01, -1.3562e+00, -7.0998e-01,  7.7957e-01, -3.8289e-01,\n",
            "          4.7722e+00,  1.3961e+00, -2.1986e+00,  1.2402e+00, -3.4728e+00],\n",
            "        [-1.7426e+00, -2.4127e+00, -1.1139e-01,  6.2229e-01, -7.5349e-01,\n",
            "          2.9038e+00, -2.3493e+00, -1.3043e+00,  6.4882e+00,  4.0041e-01],\n",
            "        [ 3.3344e+00, -5.0912e+00,  7.3193e-01, -6.6097e+00,  2.3067e+00,\n",
            "         -4.2276e-02,  2.4678e+00, -1.8324e+00,  6.2780e-02,  2.4648e+00],\n",
            "        [-1.4484e+00, -3.0046e+00, -1.8760e+00,  2.2161e+00, -6.3528e-01,\n",
            "          6.2848e+00, -2.8602e+00, -1.7816e+00,  6.7615e-01,  9.6500e-01],\n",
            "        [-4.5580e+00, -1.7816e+00, -4.9794e+00, -2.3935e+00,  7.1254e+00,\n",
            "          1.3418e+00, -8.7646e-01, -9.3362e-01, -7.3785e-01,  4.1733e+00],\n",
            "        [-4.6027e+00, -1.0006e-01, -4.7785e+00, -1.2920e+00,  5.5159e+00,\n",
            "          1.7053e+00, -1.3661e+00,  1.0994e+00, -7.9621e-01,  2.8441e+00],\n",
            "        [-3.3154e+00, -3.7915e-01,  1.6829e+00,  1.6430e+00, -2.7281e+00,\n",
            "          7.0485e-01, -6.2791e+00,  7.3726e+00,  1.2827e+00,  2.4156e+00],\n",
            "        [ 8.7988e+00, -4.7867e+00,  1.9530e-01, -3.0327e+00, -3.3259e+00,\n",
            "          1.6682e+00,  1.8309e+00,  7.8648e-02,  7.3254e-01, -1.1976e+00],\n",
            "        [-5.0365e+00, -6.3395e-01, -3.8022e+00, -2.9255e+00,  6.0026e+00,\n",
            "          1.2847e+00, -1.4661e+00,  2.8429e-02,  1.1706e+00,  3.3751e+00],\n",
            "        [-3.4948e+00, -1.0538e-01,  2.1222e-01,  7.7370e+00, -1.4827e+00,\n",
            "          2.4412e+00, -5.1319e+00,  1.5910e-01,  7.4237e-01,  3.8972e-01],\n",
            "        [-5.6965e+00,  8.3595e+00,  1.0761e+00, -6.6916e-01,  5.6651e-01,\n",
            "         -3.8027e+00, -1.4056e+00,  3.2636e+00,  2.3769e+00,  3.3277e-01],\n",
            "        [ 8.8551e+00, -4.6698e+00,  1.3940e+00, -1.6673e+00, -4.1807e+00,\n",
            "          2.3675e+00,  1.2246e+00, -5.9435e-01,  1.5188e+00, -1.9752e+00],\n",
            "        [ 1.5757e-01,  1.5510e+00,  7.5129e+00,  2.5542e+00, -5.2941e+00,\n",
            "         -1.2159e-01, -2.4083e+00,  1.6367e+00,  1.1227e+00, -3.2643e+00],\n",
            "        [-1.1268e+00,  9.8291e-01,  7.4926e+00,  1.7111e+00, -4.4254e+00,\n",
            "         -1.5618e+00, -2.7392e+00,  3.1265e+00, -4.1671e-01, -3.8644e-01],\n",
            "        [-4.1474e+00,  1.2687e+00,  2.6491e+00,  3.3805e+00, -2.9105e+00,\n",
            "         -4.1612e-01, -6.0533e+00,  8.2392e+00,  3.9063e-01,  1.6123e+00],\n",
            "        [-2.8875e+00, -1.3026e-01,  5.8913e-01,  2.7615e+00, -2.6489e+00,\n",
            "          1.3366e+00, -6.4134e+00,  9.1239e+00, -1.7789e+00,  2.4975e+00],\n",
            "        [-5.4922e-01,  1.5921e+00,  5.9725e+00, -2.1183e+00, -1.2874e+00,\n",
            "         -1.7859e+00,  1.0117e+00, -1.1557e+00,  2.3691e+00, -1.5715e+00],\n",
            "        [ 7.0243e+00, -5.0683e+00,  3.2507e-02, -3.7328e+00, -2.3873e+00,\n",
            "          2.2675e+00,  3.0265e+00, -2.1995e-01, -7.7012e-01, -1.0475e+00],\n",
            "        [-7.4402e-01,  1.4779e+00,  7.6571e+00,  2.0143e+00, -4.6400e+00,\n",
            "         -1.3842e+00, -2.1698e+00,  2.3424e+00, -4.2902e-01, -1.3422e+00],\n",
            "        [-4.6013e+00,  9.2220e+00,  2.8918e-01, -1.2816e+00,  4.9437e-01,\n",
            "         -4.6154e+00,  1.8584e-01,  2.7176e+00,  2.4126e+00,  9.7111e-02],\n",
            "        [-1.3584e+00, -4.2976e+00, -4.0746e+00,  2.3194e+00,  2.9285e-01,\n",
            "          6.4158e+00, -4.0715e+00, -1.5116e+00,  1.0473e+00,  3.2491e+00],\n",
            "        [ 7.7494e+00, -3.2695e+00,  1.6108e+00, -3.1468e-01, -4.9447e+00,\n",
            "          1.7392e+00, -8.7497e-01,  1.8624e+00,  8.3665e-01, -8.5986e-01],\n",
            "        [ 1.9059e+00, -2.4114e+00, -6.9413e-01, -2.2087e+00, -1.1223e-01,\n",
            "          2.7783e+00,  4.5184e+00, -3.3126e+00,  2.5159e+00, -3.2876e+00],\n",
            "        [-3.9403e+00, -3.9728e-01, -1.1628e+00, -2.1984e+00,  4.2906e+00,\n",
            "          2.0124e+00,  7.7715e-01, -3.3525e+00,  2.8670e+00, -4.3523e-01],\n",
            "        [-3.8271e+00,  1.6803e+00,  4.2224e+00,  3.6390e+00, -3.0862e+00,\n",
            "         -8.8878e-01, -5.4564e+00,  6.6708e+00,  1.2056e+00,  2.4911e-01],\n",
            "        [ 3.0515e+00, -1.1990e+00,  5.5015e+00,  2.5419e+00, -5.0237e+00,\n",
            "          1.8045e+00, -1.4626e-01, -5.3094e-01,  5.2546e-01, -4.0032e+00],\n",
            "        [ 9.2577e+00, -5.0381e+00,  9.4639e-01, -2.0377e+00, -4.3040e+00,\n",
            "          2.2292e+00,  1.4221e+00, -5.8099e-02,  9.1142e-01, -1.5836e+00],\n",
            "        [-2.3963e+00,  7.5961e-01,  3.2552e+00,  2.0960e+00, -3.6298e+00,\n",
            "         -3.0452e-01, -6.5557e+00,  8.9577e+00, -8.6074e-02,  1.6793e+00],\n",
            "        [-5.6146e+00,  8.0531e+00,  1.6112e+00, -1.2126e+00,  9.9441e-01,\n",
            "         -3.0341e+00, -5.0088e-01,  1.1868e+00,  2.8197e+00, -5.7689e-01],\n",
            "        [ 8.0497e+00, -5.0252e+00,  9.5539e-02, -3.6968e+00, -2.7920e+00,\n",
            "          1.6208e+00,  2.6812e+00, -1.2487e-01,  1.0965e-01, -1.0147e+00],\n",
            "        [-4.4699e+00,  1.1653e-01,  3.6878e-01,  7.7484e+00, -1.4782e+00,\n",
            "          1.8650e+00, -6.5803e+00,  2.2878e+00,  2.3332e-01,  1.5759e+00],\n",
            "        [-1.6680e+00, -8.5604e-01,  3.9263e-01,  1.5882e+00, -2.8469e+00,\n",
            "          1.5495e+00, -6.5895e+00,  9.2040e+00, -1.6165e+00,  2.7465e+00],\n",
            "        [-3.5551e+00,  3.3061e-01,  1.4037e+00,  6.7559e+00, -3.0058e+00,\n",
            "          2.0123e+00, -6.5997e+00,  4.7142e+00, -7.2589e-02,  9.2708e-01],\n",
            "        [ 2.4383e+00, -2.7180e+00, -2.0659e-01, -7.1525e+00,  3.3109e+00,\n",
            "         -4.4192e-01,  4.9099e+00, -1.8070e+00, -6.2141e-02,  1.0612e-01],\n",
            "        [-2.5322e+00,  1.7403e+00,  1.1177e+00,  7.7065e+00, -3.2340e+00,\n",
            "          2.2191e+00, -3.8018e+00,  2.3035e-01,  2.5141e-01, -1.5671e+00],\n",
            "        [ 6.4034e-01,  7.4501e-01,  7.8757e+00,  1.9237e+00, -5.3257e+00,\n",
            "         -3.9718e-01, -2.3917e+00,  1.9691e+00,  1.0837e+00, -2.9311e+00],\n",
            "        [-2.7610e+00, -3.1297e+00, -3.5241e+00, -3.0833e+00,  3.4393e+00,\n",
            "          1.2795e+00, -2.4486e+00,  1.2304e+00, -1.0044e+00,  7.3296e+00],\n",
            "        [-3.2333e+00,  1.0137e+00,  6.3569e-01,  8.0358e+00, -2.1287e+00,\n",
            "          2.1052e+00, -4.5802e+00, -1.0378e-01,  5.4475e-01, -6.1120e-01],\n",
            "        [-2.8856e+00,  5.5133e+00,  2.9678e+00, -5.2606e-01, -2.5021e-01,\n",
            "         -2.2717e+00,  1.0932e+00, -2.0197e+00,  3.3009e+00, -2.4585e+00],\n",
            "        [-3.5125e-01,  2.4327e+00,  6.9819e+00,  3.0786e+00, -5.2061e+00,\n",
            "         -5.7376e-01, -2.4468e+00,  2.1130e+00,  7.6074e-01, -3.0579e+00],\n",
            "        [-4.1613e+00, -3.5192e+00, -1.8416e+00, -4.5199e+00,  6.9971e+00,\n",
            "          9.7451e-01,  2.9676e-01, -2.2805e+00, -4.7880e-01,  3.6721e+00],\n",
            "        [-5.0810e+00,  7.9730e+00, -3.0354e-02, -1.0327e+00,  9.7313e-01,\n",
            "         -3.8525e+00, -8.6925e-01,  2.9395e+00,  3.3068e+00,  7.7994e-01],\n",
            "        [-3.3738e+00,  2.9653e-01,  1.7325e-01,  7.9927e+00, -1.5813e+00,\n",
            "          2.2498e+00, -5.1483e+00, -1.4091e-03,  6.5335e-01,  2.0625e-01]])\n"
          ]
        }
      ]
    }
  ]
}